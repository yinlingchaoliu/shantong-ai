{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 这节课会带给你\n",
    "\n",
    "1. 了解机器学习的基本概念\n",
    "2. 掌握模型微调/小参数量微调的操作过程\n",
    "3. 掌握模型微调/小参数量微调关键「超参」\n",
    "4. 掌握训练数据的选择、准备、清洗等方法与思路\n",
    "5. 训练一个垂直领域的大模型\n",
    "\n",
    "开始上课！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 还是写在前面\n",
    "\n",
    "1. 这堂课内容有难度：\n",
    "   1. 有很多陌生的名词，包括数学名词和模型算法本身的名词\n",
    "   2. 涉及到很多数学知识，很多东西本身是从数学推导出来的，不好具象化\n",
    "   3. 深度学习里有大量基于经验的总结，体现成各种超参和 Tricks\n",
    "2. 这堂课该怎么学：\n",
    "   1. 注意力集中，跟上我的思路\n",
    "   2. 遇到不懂的地方，别害怕，先尝试思考\n",
    "   3. 实现想不明白也别灰心，这个领域的能力积累是需要时间的\n",
    "   4. 真感兴趣的同学，尝试多度论文，“书读百遍其义自见”的道理我亲自验证过\n",
    "3. 自己思考很重要！回想“程序员思维向算法工程师思维”的转变\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning 有什么用：先看一个例子\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://u202774-9847-a4dc9da1.westb.seetacloud.com:8443/\n",
    "\n",
    "**法律领域的阅读理解**\n",
    "\n",
    "判决书:\n",
    "\n",
    "经审理查明:2004 年 1 月 6 日,安居物业与东至县昌盛房地产开发有限责任公司签订前期物业管理服务合同,合同约定由安居物业对东至县昌盛房地产开发有限责任公司开发的食品小区提供物业服务,服务期限为该小区业主大会成立时止,该合同对委托管理事项、双方的权利义务、物业管理服务要求标准、物业管理服务费用、违约责任等进行了具体的约定 2005 年 8 月 28 日,汪 x3 入住该小区 8 栋一单元 102 室,并与安居物业签订了房屋入住协议,约定物业管理费为 252 元/年,并明确若汪 x3 无故不交规定应交费用的,安居物业可要求其限期缴纳并收取应缴费用 3%的滞纳金汪 x3 自 2008 年 8 月 28 日以来未交纳物业服务费,2013 年 12 月,安居物业向汪 x3 下达催交物业服务费通知书现安居物业以被告自 2008 年 8 月 28 日起至 2015 年 4 月 27 日止的物业服务费 1680 元及违约金 50.4 元未交为由诉至本院,被告则以原告不作为为由拒不缴纳,为此成讼另查明,本案所涉食品小区目前未选举业主委员会以上事实有当事人陈述、前期物业管理服务合同、房屋入住协议等证据在卷佐证,足以认定\n",
    "\n",
    "问题 1: 安居物业给哪个小区做物业？\n",
    "\n",
    "问题 2: 被告是否如约支付物业费了？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 我有很多问题\n",
    "\n",
    "<br/>\n",
    "<img src=\"confused.png\" style=\"margin-left: 0px\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、什么是：\n",
    "\n",
    "- 模型训练（Training）\n",
    "- 预训练（Pre-Training）\n",
    "- 微调（Fine-Tuning）\n",
    "- 轻量化微调（Parameter Efficient Fine-Tuning, PEFT）\n",
    "\n",
    "<br/>\n",
    "<img src=\"training.png\" style=\"margin-left: 0px\" width=\"800px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、什么是模型\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>尝试：</b> 用简单的数学语言表达概念\n",
    "</div>\n",
    "\n",
    "### 2.1、通俗（不严谨）的说、模型是一个函数：\n",
    "\n",
    "$y=F(x;\\omega)$\n",
    "\n",
    "- 它接收输入$x$：可以是一个词、一个句子、一篇文章或图片、语音、视频 ...\n",
    "  - 这些物体都被表示成一个数学「矩阵」（其实应该叫张量，tensor）\n",
    "- 它预测输出$y$\n",
    "  - 可以是「是否」（{0,1}）、标签（{0,1,2,3...}）、一个数值（回归问题）、下一个词的概率 ...\n",
    "- 它的表达式就是网络结构（这里特指深度学习）\n",
    "- 它有一组参数$\\omega$，这就是我们要训练的部分\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>把它想象成一个方程：</b> \n",
    "    <ol>\n",
    "        <li>每条数据就是一对儿 $(x,y)$ ，它们是常量</li>\n",
    "        <li>参数是未知数，是变量</li>\n",
    "        <li>$F$ 就是表达式：我们不知道真实的公式是什么样的，所以假设了一个足够复杂的公式（比如，一个特定结构的神经网络）</li>\n",
    "        <li>这个求解这个方程（近似解）就是训练过程</li>\n",
    "    </ol>\n",
    "</div>\n",
    "\n",
    "### 2.2、一个最简单的神经网络\n",
    "\n",
    "一个神经元：$y=f(\\sum_i w_i\\cdot x_i)$\n",
    "\n",
    "<img src=\"neuron.jpg\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "把很多神经元连接起来，就成了神经网络：$y=f(\\sum_i w_i\\cdot x_i)$、$z=f(\\sum_i w'_i\\cdot y_i)$、$\\tau=f(\\sum_i w''_i\\cdot z_i)$、...\n",
    "\n",
    "<img src=\"network.jpg\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "这里的$f$叫激活函数，有很多种形式\n",
    "\n",
    "<img src=\"activation.jpeg\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考：</b> 这里如果没有激活函数会怎样？\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、什么是模型训练\n",
    "\n",
    "我们希望找到一组参数$\\omega$，使模型预测的输出$\\hat{y}=F(x;\\omega)$与真实的输出$y$，尽可能的接近\n",
    "\n",
    "这里，我们（至少）需要两个要素：\n",
    "\n",
    "- 一个数据集，包含$N$个输入输出的例子（称为样本）：$D=\\{(x_i,y_i)\\}_{i=1}^N$\n",
    "- 一个损失函数，衡量模型预测的输出与真实输出之间的差距：$\\mathrm{loss}(y,F(x;\\omega))$\n",
    "\n",
    "### 3.1、模型训练本质上是一个求解最优化问题的过程\n",
    "\n",
    "$\\min_{\\omega} L(D,\\omega)$\n",
    "\n",
    "$L(D,\\omega)=\\frac{1}{N}\\sum_{i=1}^N\\mathrm{loss}(y,F(x;\\omega))$\n",
    "\n",
    "### 3.2、怎么求解\n",
    "\n",
    "回忆一下梯度的定义\n",
    "\n",
    "<img src=\"gradient.svg\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "\n",
    "从最简单的情况说起：梯度下降与凸问题\n",
    "\n",
    "<img src=\"gradient.png\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "梯度决定了函数变化的方向，每次迭代更新我们会收敛到一个极值\n",
    "\n",
    "$\\omega_{n+1}\\leftarrow \\omega_n - \\gamma \\nabla_{\\omega}L(D,\\omega)$\n",
    "\n",
    "其中，$\\gamma<1$叫做学习率，它和梯度的模数共同决定了每步走多远\n",
    "\n",
    "### 3.3、**现实总是没那么简单（1）**：在整个数据集上求梯度，计算量太大了\n",
    "\n",
    "<br/>\n",
    "<img src=\"batch.png\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>条件允许的情况下，Batch Size尽量大些\n",
    "</div>\n",
    "\n",
    "### 3.4、**现实总是没那么简单（2）**：深度学习没有全局最优解（非凸问题）\n",
    "\n",
    "<br/>\n",
    "<img src=\"local_minima.png\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "### 3.5、**现实总是没那么简单（3）**：学习率也很关键，甚至需要动态调整\n",
    "\n",
    "<br/>\n",
    "<img src=\"lr.png\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>适当调整学习率（Learning Rate），避免陷入很差的局部解或者跳过了好的解\n",
    "</div>\n",
    "\n",
    "### 3.6、神经网络的梯度怎么求（选学）\n",
    "\n",
    "Chain Rule:\n",
    "\n",
    "假设 $L(w)=f(g(h(w)))$\n",
    "\n",
    "那么 $L'(w)=f'(g(h(w))) \\cdot g'(h(w)) \\cdot h'(w)$\n",
    "\n",
    "<img src=\"backprop.png\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "蓝色的过程叫 Forward Pass，红色的过程叫 Backward Pass，整个过程叫 Backpropagation\n",
    "\n",
    "## 四、求解器\n",
    "\n",
    "为了让训练过程更好的收敛，人们设计了很多更复杂的求解器\n",
    "\n",
    "- 比如：SGD、L-BFGS、Rprop、RMSprop、Adam、AdamW、AdaGrad、AdaDelta 等等\n",
    "- 但是，好在最常用的就是 Adam 或者 AdamW\n",
    "\n",
    "## 五、一些常用的损失函数\n",
    "\n",
    "- 两个数值的差距，Min Square Error：$\\ell_{\\mathrm{MSE}}=\\frac{1}{N}\\sum_{i=1}^N(y_i-\\hat{y}_i)^2$ (等价于欧式距离，见下文)\n",
    "- 两个向量之间的（欧式）距离：$\\ell(\\mathbf{y},\\mathbf{\\hat{y}})=\\|\\mathbf{y}-\\mathbf{\\hat{y}}\\|$\n",
    "- 两个向量之间的夹角（余弦距离）：\n",
    "  <img src=\"cosine_loss.png\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "\n",
    "- 两个概率分布之间的差异，交叉熵：$\\ell_{\\mathrm{CE}}(p,q)=-\\sum_i p_i\\log q_i$ ——假设是概率分布 p,q 是离散的\n",
    "- 这些损失函数也可以组合使用（在模型蒸馏的场景常见这种情况），例如$L=L_1+\\lambda L_2$，其中$\\lambda$是一个预先定义的权重，也叫一个「超参」\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考：</b> 你能找到这些损失函数和分类、聚类、回归问题之间的关系吗？\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、用 PyTorch 训练一个最简单的神经网络\n",
    "\n",
    "数据集（MNIST）样例：\n",
    "\n",
    "<img src=\"MNIST.jpg\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "输入一张 28×28 的图像，输出标签 0--9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "TEST_BACTH_SIZE = 1000\n",
    "EPOCHS = 5\n",
    "LR = 0.01\n",
    "GAMMA = 0.9\n",
    "WEIGHT_DECAY = 1e-6\n",
    "SEED = 42\n",
    "LOG_INTERVAL = 100\n",
    "\n",
    "# 定义一个全连接网络\n",
    "\n",
    "\n",
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 第一层784维输入、256维输出 -- 图像大小28×28=784\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        # 第二层256维输入、128维输出\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        # 第三层128维输入、64维输出\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        # 第三层64维输入、10维输出 -- 输出类别10类（0,1,...9）\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 把输入展平成1D向量\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # 每层激活函数是ReLU，额外加dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # 输出为10维概率分布\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "# 训练过程\n",
    "\n",
    "\n",
    "def train(model, loss_fn, device, train_loader, optimizer, epoch):\n",
    "    # 开启梯度计算\n",
    "    model.train()\n",
    "    for batch_idx, (data_input, true_label) in enumerate(train_loader):\n",
    "        # 从数据加载器读取一个batch\n",
    "        # 把数据上载到GPU（如有）\n",
    "        data_input, true_label = data_input.to(device), true_label.to(device)\n",
    "        # 求解器初始化（每个batch初始化一次）\n",
    "        optimizer.zero_grad()\n",
    "        # 正向传播：模型由输入预测输出\n",
    "        output = model(data_input)\n",
    "        # 计算loss\n",
    "        loss = loss_fn(output, true_label)  # F.nll_loss(output, target)\n",
    "        # 反向传播：计算当前batch的loss的梯度\n",
    "        loss.backward()\n",
    "        # 由求解器根据梯度更新模型参数\n",
    "        optimizer.step()\n",
    "\n",
    "        # 间隔性的输出当前batch的训练loss\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data_input), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "# 计算在测试集的准确率和loss\n",
    "def test(model, loss_fn, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += loss_fn(output, target, reduction='sum').item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 检查是否有GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    # 设置随机种子（以保证结果可复现）\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "    # 训练设备（GPU或CPU）\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    # 设置batch size\n",
    "    train_kwargs = {'batch_size': BATCH_SIZE}\n",
    "    test_kwargs = {'batch_size': TEST_BACTH_SIZE}\n",
    "\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    # 数据预处理（转tensor、数值归一化）\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    # 自动下载MNIST数据集\n",
    "    dataset_train = datasets.MNIST('data', train=True, download=True,\n",
    "                                   transform=transform)\n",
    "    dataset_test = datasets.MNIST('data', train=False,\n",
    "                                  transform=transform)\n",
    "\n",
    "    # 定义数据加载器（自动对数据加载、多线程、随机化、划分batch、等等）\n",
    "    train_loader = torch.utils.data.DataLoader(dataset_train, **train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset_test, **test_kwargs)\n",
    "\n",
    "    # 创建神经网络模型\n",
    "    model = FeedForwardNet().to(device)\n",
    "\n",
    "    # 指定求解器\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    # scheduler = StepLR(optimizer, step_size=1, gamma=GAMMA)\n",
    "\n",
    "    # 定义loss函数\n",
    "    loss_fn = F.cross_entropy\n",
    "\n",
    "    # 训练N个epoch\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train(model, loss_fn, device, train_loader, optimizer, epoch)\n",
    "        test(model, loss_fn, device, test_loader)\n",
    "        # scheduler.step()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>如何运行这段代码：</b>\n",
    "<ol>\n",
    "    <li>不要在Jupyter笔记上直接运行</li>\n",
    "    <li>请将左侧的 exp.py 文件下载到本地</li>\n",
    "    <li>安装相关依赖包: pip install torch torchvision</li>\n",
    "    <li>运行：python3 exp.py</li>\n",
    "</ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七、先介绍几个常用的超参\n",
    "\n",
    "### 7.1、过拟合与欠拟合\n",
    "\n",
    "<br />\n",
    "<img src=\"overfit.png\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>奥卡姆剃刀：</b> 两个处于竞争地位的理论能得出同样的结论，那么简单的那个更好。\n",
    "</div>\n",
    "\n",
    "**防止过拟合的方法（1）：**Weight Decay\n",
    "\n",
    "$J(\\omega)=L(D,\\omega)+\\lambda\\|\\omega\\| \\Rightarrow \\nabla_{\\omega}J=\\nabla_{\\omega}L + \\frac{1}{2}\\lambda\\omega$\n",
    "\n",
    "- 惩罚参数的复杂性（$L_2$-norm）：等价与在梯度上减去参数本身（乘一个小数作为权重）\n",
    "- Weight Decay 就是前面那个权重$\\lambda$\n",
    "\n",
    "**防止过拟合的方法（2）：**Dropout\n",
    "\n",
    "- 我们在前向传播的时候，概率性的（临时）删除一部分神经元，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征\n",
    "- 这样训练$N$次，等价于训练$N$不同的网络，再取平均值；$N$个网络不会同时过拟合于与一个结果，这样平均值的方式能有效减少过拟合的干扰。\n",
    "\n",
    "<img src=\"dropout.jfif\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "\n",
    "### 7.2、学习率调整策略\n",
    "\n",
    "- 开始时学习率大些：快速到达最优解附近\n",
    "- 逐渐减小学习率：避免跳过最优解\n",
    "- NLP 任务的损失函数有很多“悬崖峭壁”，自适应学习率更能处理这种极端情况，避免梯度爆炸。\n",
    "\n",
    "<img src=\"scheduler.png\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "\n",
    "几种常用的学习率调整器\n",
    "\n",
    "<img src=\"lr_scheduler.jpg\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "\n",
    "**防止过拟合的方法（3）：**学习率 Warm Up\n",
    "\n",
    "先从一个很小的学习率逐渐上升到正常学习率，在稳步减小学习率\n",
    "\n",
    "- 其原理尚未被充分证明\n",
    "- 经验主义解释：减缓模型在初始阶段对 mini-batch 的提前过拟合现象，保持分布的平稳\n",
    "- 经验主义解释：有助于保持模型深层的稳定性\n",
    "\n",
    "<img src=\"warmup.png\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>应用场景：</b> (1) 当网络非常容易nan时候；(2) 如果训练集损失很低，准确率高，但测试集损失大，准确率低. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 八、自然语言处理常见的网络结构\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考：</b> 图像天生可以表示成矩阵（或tensor），那文本怎么表示成矩阵（或tensor）\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1、文本卷积神经网络 TextCNN\n",
    "\n",
    "<br />\n",
    "\n",
    "一个窗口的卷积和Pooling过程\n",
    "\n",
    "<img src=\"conv_maxpooling_steps.gif\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "不同大小的窗口分别做卷积和Pooling，结果拼在一起\n",
    "\n",
    "<img src=\"TextCNN.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "- 参数量较少、好训练、算力要求低\n",
    "- 适合文本分类问题\n",
    "- 善于表示局部特征（卷积窗口），不擅长表示长上下文依赖关系\n",
    "\n",
    "### 8.2、循环神经网络 RNN\n",
    "\n",
    "<br />\n",
    "\n",
    "首先：输入是一个序列\n",
    "\n",
    "<img src=\"RNN.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "但这种简易 RNN 有很多问题，最大问题是随着序列长度增加，梯度消失或爆炸\n",
    "\n",
    "<img src=\"LSTM.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "LSTM 和 GRU 通过「门」来控制上文的状态被记住还是遗忘，同时防止梯度消失或爆炸\n",
    "\n",
    "以LSTM为例：\n",
    "\n",
    "<img src=\"lstm.jfif\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "### 8.3、Attention (for RNN)\n",
    "\n",
    "<br />\n",
    "\n",
    "给定当前的输入，上文的一些信息比另一些重要\n",
    "\n",
    "<img src=\"attention.gif\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "<br />\n",
    "\n",
    "<font color='blue'>于是设计一个可微的函数就可以把它加入到网络中来试试，反正也没有全局最优解</font>\n",
    "\n",
    "<br />\n",
    "<img src=\"attention-fn.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "- 对当前 token $t$的上文的每个 token $i$计算上述 score\n",
    "- 将这些 score 做 softmax 得到权重$\\alpha_{t,i}$\n",
    "- 将上文的隐层状态乘以其权重并相加$c_t=\\sum_i\\alpha_{t,i}h_i$\n",
    "- 将$c_t$与当前 token 的状态拼接在一起$s_t=\\mathrm{concat}(h_t,c_t)$\n",
    "- 激活输出$y_t=\\sigma(s_t)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 九、Transformer 江山一统\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考：</b> RNN有什么缺点？大模型为什么不是很多层RNN？\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "<img src=\"transformer.gif\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "### 9.1、**消除恐惧：**我们亲手写一个 Transformer\n",
    "\n",
    "### 9.1.1、Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, max_len=512):\n",
    "        super().__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, embed_size).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, embed_size, 2).float()\n",
    "                    * -(math.log(10000.0) / embed_size)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class BERTEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param vocab_size: 词表大小\n",
    "        :param embed_size: embedding维度768\n",
    "        :param dropout: dropout概率\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(\n",
    "            vocab_size, embed_size, padding_idx=0)\n",
    "        self.position_embedding = PositionalEmbedding(\n",
    "            embed_size=embed_size, max_len=512)\n",
    "        self.token_type_embedding = nn.Embedding(2, embed_size, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        x = self.token_embedding(input_ids) + self.position_embedding(\n",
    "            input_ids) + self.token_type_embedding(token_type_ids)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.2、单头 Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import math\n",
    "\n",
    "'''\n",
    "query = query_linear(x)\n",
    "key = key_linear(x)\n",
    "value = value_linear(x)\n",
    "'''\n",
    "\n",
    "# 单个头的注意力计算\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "\n",
    "    def forward(self, query, key, value, mask=None, dropout=None):\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "            / math.sqrt(query.size(-1))\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        p_attn = F.softmax(scores, dim=-1)\n",
    "\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "\n",
    "        return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "每个token对应的query向量与每个token对应的key向量做内积\n",
    "\n",
    "<img src=\"kq2.gif\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "<br />\n",
    "将上述内积取softmax（得到0~1之间的值，即为attention权重）\n",
    "\n",
    "<img src=\"kq_softmax.gif\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "<br />\n",
    "计算每个token相对于所有其它token的attention权重（最终构成一个$L\\times L$的attention矩阵）\n",
    "\n",
    "<img src=\"kq_softmax2.gif\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "<br />\n",
    "每个token对应的value向量乘以attention权重，并相加，得到当前token的self-attention value向量\n",
    "\n",
    "<img src=\"v.gif\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "<br />\n",
    "将上述操作应用于每个token\n",
    "<img src=\"v2.gif\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "<br />\n",
    "以上是一个头的操作，同时（并行）应用于多个独立的头\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.3、多头 Attention\n",
    "\n",
    "将每个头得到向量拼接在一起，最后乘一个线性矩阵，得到 multi-head attention 的输出\n",
    "\n",
    "<img src=\"multi-head.gif\" style=\"margin-left: 0px\" width=\"800px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, head_num, hidden_size, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param head_num: 头的个数，必须能被hidden_size整除\n",
    "        :param hidden_size: 隐层的维度，与embed_size一致\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert hidden_size % head_num == 0\n",
    "\n",
    "        self.per_head_dim = hidden_size // head_num\n",
    "        self.head_num = head_num\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.query_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.key_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.value_linear = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        self.output_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.attention = Attention()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def reshape(self, x, batch_size):\n",
    "        # 拆成多个头\n",
    "        return x.view(batch_size, -1, self.head_num, self.per_head_dim).transpose(1, 2)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        query = self.reshape(self.query_linear(x))\n",
    "        key = self.reshape(self.key_linear(x))\n",
    "        value = self.reshape(self.value_linear(x))\n",
    "\n",
    "        # 每个头计算attention\n",
    "        x, attn = self.attention(\n",
    "            query, key, value, mask=mask, dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        # 把每个头的attention*value拼接在一起\n",
    "        x = x.transpose(1, 2).contiguous().view(\n",
    "            batch_size, -1, self.hidden_size)\n",
    "\n",
    "        # 乘一个线性矩阵\n",
    "        return self.output_linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.4、全连接网络（Feed-Forward Network）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, dropout=0.1):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.input_layer = nn.Linear(hidden_size, hidden_size*4)\n",
    "        self.output_layer = nn.Linear(hidden_size*4, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.5、拼成一层 Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, head_num, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.multi_head_attention = MultiHeadedAttention(head_num, hidden_size)\n",
    "        self.feed_forward = FeedForward(hidden_size, dropout=dropout)\n",
    "        self.layer_norm1 = nn.LayerNorm(hidden_size)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.layer_norm2 = nn.LayerNorm(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x0 = x\n",
    "        # 多头注意力层\n",
    "        x = self.multi_head_attention(x, mask)\n",
    "\n",
    "        # 残差和LayerNorm层(1)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.layer_norm1(x0+x)\n",
    "\n",
    "        # 前向网络层\n",
    "        x1 = x\n",
    "        x = self.feed_forward(x)\n",
    "\n",
    "        # 残差和LayerNorm层(2)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.layer_norm2(x1+x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "Multi-head attention的输出，经过残差和norm之后进入一个两层全连接网络\n",
    "<img src=\"ffn.gif\" style=\"margin-left: 0px\" width=\"800px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layernorm:\n",
    "\n",
    "$y=\\frac{x-\\mathrm{E}(x)}{\\sqrt{\\mathrm{Var}(x)+\\epsilon}}*\\gamma+\\beta$\n",
    "\n",
    "其中 $\\gamma$ 和 $\\beta$ 是可训练的参数，$\\epsilon=10^{-5}$是超参，保持数值稳定性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.6、多层 Transformer 构成 BERT Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class BERT(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, hidden_size=768, layer_num=12, head_num=12, dropout=0.1):\n",
    "\n",
    "        super().__init__()\n",
    "        # Embedding层\n",
    "        self.embedding = BERTEmbedding(\n",
    "            vocab_size=vocab_size, embed_size=hidden_size)\n",
    "        # N层Transformers\n",
    "        self.transformer_blocks = nn.ModuleList(\n",
    "            [TransformerBlock(hidden_size, head_num, dropout)\n",
    "             for _ in range(layer_num)]\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        \"\"\"\n",
    "        tokenizer([\"你好吗\",\"你好\"], text_pair=[\"我很好\",\"我好\"], max_length=10, padding='max_length',truncation=True)\n",
    "        [CLS]你好吗[SEP]我很好[SEP][PAD]\n",
    "        [CLS]你好[SEP]我好[SEP][PAD][PAD][PAD]  \n",
    "        input_ids: [\n",
    "            [101, 872, 1962, 1408, 102, 2769, 2523, 1962, 102, 0],\n",
    "            [101, 872, 1962, 102, 2769, 1962, 102, 0, 0, 0]\n",
    "        ]\n",
    "        token_type_ids：[\n",
    "                [0, 0, 0, 0, 0, 1, 1, 1, 1, 0],\n",
    "                [0, 0, 0, 0, 1, 1, 1, 0, 0, 0]\n",
    "            ]\n",
    "        \"\"\"\n",
    "        attention_mask = (x > 0).unsqueeze(\n",
    "            1).repeat(1, x.size(1), 1).unsqueeze(1)\n",
    "\n",
    "        # 计算embedding\n",
    "        x = self.embedding(input_ids, token_type_ids)\n",
    "\n",
    "        # 逐层代入Tranformers\n",
    "        for transformer in self.transformer_blocks:\n",
    "            x = transformer.forward(x, attention_mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Transformer 怎么用\n",
    "\n",
    "### 9.2.1. Encoder-Only LM 用于文本表示\n",
    "\n",
    "针对不同下游任务，在 Encoder 上面添加不同的输出层\n",
    "<br />\n",
    "<img src=\"BERT.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "BERT-BiLSTM-CRF一个序列标注的经典网络结构\n",
    "\n",
    "<img src=\"bert-bilstm-crf.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "### 9.2.2. Encoder-Decoder LM，机器翻译/文本生成（大语言模型的一种形态）\n",
    "\n",
    "- Decoder 也是 N 层 transformer 结构\n",
    "- 生成一个 token，把它加入上文，再生成下一个 token，以此类推\n",
    "  <br />\n",
    "  <img src=\"decoder1.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "Decoder 的每个 token 与 encoder 最后一层的输出和 decoder 上文的 token 一起做 attention\n",
    "<br />\n",
    "<img src=\"decoder2.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "Decoder 的 token 只能 attend 到上文的 token（因为此时下文还没有出现）\n",
    "<br />\n",
    "<img src=\"decoder3.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "### 9.2.3. Decoder-Only LM 也叫 Causal LM 或 Left-to-right LM（GPT 家族）\n",
    "\n",
    "<br />\n",
    "<img src=\"decoder4.png\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "\n",
    "### 9.2.4. 大语言模型族谱\n",
    "\n",
    "<br />\n",
    "<img src=\"llm.jpg\" style=\"margin-left: 0px\" width=\"800px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[继续](huggingface/index.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
