{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 💡 这节课会带给你\n",
    "\n",
    "1. LangChain.js 的特点和基本用法\n",
    "2. Semantic Kernel 的特点和基本用法\n",
    "3. 如何选择适合自己的 LLM 开发平台\n",
    "4. 如何给开源软件贡献代码\n",
    "\n",
    "开始上课！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 大语言模型开发平台的价值是什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有平台的价值，都是提升便利性，降低开发成本。\n",
    "\n",
    "大语言模型开发平台的价值，就是让开发者可以更方便地开发基于大语言模型的应用，尤其在更换模型时不需要重新开发。\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>中国国情下，特别需要 LangChain 类的框架，因为我们没有「唯一」好用的大模型。\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LangChain vs. Semantic Kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先比较下影响力。\n",
    "\n",
    "<img src=\"star-history.png\" width=\"700\"/>\n",
    "\n",
    "数据来源：https://star-history.com/#langchain-ai/langchain&microsoft/semantic-kernel&hwchase17/langchainjs&minimaxir/simpleaichat&Date\n",
    "\n",
    "LangChain 完胜？让我们仔细看看。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LangChain.js\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 版 LangChain 的姊妹项目，都是由 Harrison Chase 主理。\n",
    "\n",
    "项目地址：https://github.com/hwchase17/langchainjs\n",
    "\n",
    "文档地址：https://js.langchain.com/docs/\n",
    "\n",
    "特色：\n",
    "\n",
    "1. 可以和 Python 版 LangChain 无缝对接\n",
    "2. 抽象设计完全相同，概念一一对应\n",
    "3. 所有对象序列化后都能跨语言使用\n",
    "4. 但 API 差别挺大，不过在努力对齐\n",
    "\n",
    "支持环境：\n",
    "\n",
    "1. Node.js (ESM and CommonJS) - 18.x, 19.x, 20.x\n",
    "2. Cloudflare Workers\n",
    "3. Vercel / Next.js (Browser, Serverless and Edge functions)\n",
    "4. Supabase Edge Functions\n",
    "5. Browser\n",
    "6. Deno\n",
    "\n",
    "安装：\n",
    "\n",
    "```bash\n",
    "npm install langchain\n",
    "```\n",
    "\n",
    "当前重点：\n",
    "\n",
    "1. 追上 Python 版的能力\n",
    "2. 保持兼容尽可能多的环境\n",
    "3. 对质量关注不多，随时间自然能解决\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 两个防坑指南\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 版本升级坑\n",
    "\n",
    "如果想 `npm update` 能更新 LangChain.js 到最新版，需要修改 `package.json`：\n",
    "\n",
    "```diff\n",
    "- \"langchain\": \"^0.0.110\",\n",
    "+ \"langchain\": \"~0.0.110\",\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文档坑\n",
    "\n",
    "文档真的挺差的，稍微用深一些，就得读读源码才行。\n",
    "\n",
    "比如最核心的一个函数，向 OpenAI 发出请求：https://js.langchain.com/docs/api/chat_models_openai/classes/ChatOpenAI#call\n",
    "\n",
    "![call](call.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 例子：chatall.ts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[chatall.ts](chatall/chatall.ts) 使用 LangChain.js 的 PromptTemplate 和 ChatOpenAI、ChatBaiduWenxin，测试批量 prompt 在不同大模型下的效果。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 简单了解下 LangChainHub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "开源网址：https://github.com/hwchase17/langchain-hub\n",
    "\n",
    "野心之作。把好的 prompt、chain 和 agent 以 JSON 格式共享。使用只需：\n",
    "\n",
    "### Python\n",
    "\n",
    "```python\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "llm = ...\n",
    "tools = ...\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"lc://agents/self-ask-with-search/agent.json\")\n",
    "```\n",
    "\n",
    "### TypeScript\n",
    "\n",
    "```typescript\n",
    "import { loadAgent } from \"langchain/agents/load\";\n",
    "\n",
    "const llm = ...;\n",
    "const tools = ...;\n",
    "\n",
    "const agent = loadAgent(\n",
    "    \"lc://agents/self-ask-with-search/agent.json\",\n",
    "    {\n",
    "        llm,\n",
    "        tools,\n",
    "    }\n",
    ");\n",
    "```\n",
    "\n",
    "但这个项目可能废了，最后更新截至 2023-04-13。但这个思路值得深思。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LangChainHub 的启示\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChainHub 解决的真需求是：**prompt、chain 和 agent 的定义都是可以「数据化」的。**\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>未来产品经理和研发的分工：</b>\n",
    "<li>产品经理定义 prompt、chain、agent（简称 PCA），研发开发调试环境和生产环境</li>\n",
    "<li>PCA 的定义数据保存在独立 repo，独立进行版本管理，和代码解耦</li>\n",
    "<li>无需传统上线发布行为，就能改变产品的行为。这是另一种「热更新」</li>\n",
    "<li>以上工作就算都是一个人做，也值得解耦</li>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>LangChain 做为 LLM 应用的浪尖项目，尽管它有很多缺点，但它所做的每件事，一定有真实需求在背后。就算不用 LangChain，也要学习它的思路，了解它的变化，推测前沿需求。\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 一种关注：LangSmith\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非开源的商业 SaaS 项目：https://www.langchain.com/langsmith\n",
    "\n",
    "- 7 月 18 日发布：https://blog.langchain.dev/announcing-langsmith/\n",
    "- 在线测试、调试和监视 LLM 应用\n",
    "- 我今天下午刚拿到测试权……\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Semantic Kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先比较下 Semantic Kernel 和 LangChain。\n",
    "\n",
    "|          | Semantic Kernel              | LangChain          |\n",
    "| -------- | ---------------------------- | ------------------ |\n",
    "| 出品公司 | 微软                         | LangChain AI       |\n",
    "| 支持语言 | Python、C#、Java、TypeScript | Python、TypeScript |\n",
    "| 开源协议 | MIT                          | MIT                |\n",
    "| 被应用在 | Microsoft 365 Copilot、Bing  | 1.5w+ 开源项目     |\n",
    "\n",
    "当下，LangChain 更强。但 Semantic Kernel 可能更有未来，因为：\n",
    "\n",
    "1. 不要怀疑微软要做 AI 霸主的决心\n",
    "2. 不要轻视微软的架构和工程能力\n",
    "3. 以及，钞能力\n",
    "\n",
    "但微软的非中立性，可能带来问题。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SK 的开发进展\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. C# 版最成熟：https://github.com/microsoft/semantic-kernel\n",
    "2. Python 版也可用，但正在重构：https://github.com/microsoft/semantic-kernel\n",
    "3. Java 版实验阶段：https://github.com/microsoft/semantic-kernel/tree/experimental-java\n",
    "4. TypeScript 版……：https://github.com/microsoft/semantic-kernel/tree/experimental-typescript\n",
    "5. 文档写得特别好，但追不上代码更新速度：\n",
    "   - 更多讲解：https://learn.microsoft.com/en-us/semantic-kernel/overview/\n",
    "   - 更偏实操：https://github.com/microsoft/semantic-kernel/blob/main/samples/notebooks/python/00-getting-started.ipynb\n",
    "\n",
    "这里可以了解最新进展：https://learn.microsoft.com/en-us/semantic-kernel/get-started/supported-languages\n",
    "\n",
    "不同语言之间的概念都是相通的。本课程以 Python 版为例。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SK 的生态位\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与 LangChain 完全重叠。\n",
    "\n",
    "<img src=\"copilot-stack.png\" alt=\"SK 的生态位\" width=\"300\"/>\n",
    "\n",
    "解释：\n",
    "\n",
    "- Plugin extensibility: 插件扩展\n",
    "- Copilots: AI 助手（副驾驶），例如 GitHub Copilot、Office 365 Copilot、Windows Copilot\n",
    "- AI orchestration: AI 编排，SK 就在这里\n",
    "- Foundation models: 基础大模型，例如 GPT-4\n",
    "- AI infrastructure: AI 基础设施，例如 PyTorch、GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SK 基础架构\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SK 架构](mind-and-body-of-semantic-kernel.png)\n",
    "\n",
    "解释：\n",
    "\n",
    "- Models and Memory: 和 LangChain 的概念相同，类比为大脑\n",
    "- Connectors: 用来连接各种外部服务，类似驱动程序\n",
    "- Plugins: 用来连接内部技能\n",
    "- Triggers and actions: 外部系统的触发器和动作，类比为四肢\n",
    "\n",
    "Semantic Kernel 用 **Kernel** 命名，是因为它确实像个操作系统 kernel，做核心资源调配，各种资源都可以挂在它上。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SK vs. LangChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概念对照\n",
    "\n",
    "| LangChain        | Semantic Kernel  |\n",
    "| ---------------- | ---------------- |\n",
    "| Model            | Connector        |\n",
    "| Tools            | Connector        |\n",
    "| Vectorstore      | Connector        |\n",
    "| Memory           | Memory           |\n",
    "| Prompt Templates | Plugins          |\n",
    "| Chain            | Pipeline / Chain |\n",
    "| Agent            | Planner          |\n",
    "| TextSplitter     | text.\\*          |\n",
    "| OutputParser     | 无               |\n",
    "\n",
    "### 功能对照\n",
    "\n",
    "|            | LangChain | Semantic Kernel |\n",
    "| ---------- | --------: | --------------: |\n",
    "| 大模型     |       60+ |              5+ |\n",
    "| 向量数据库 |       40+ |              11 |\n",
    "| Agent      |       10+ |               4 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 环境搭建\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 安装 Python 3.x：https://www.python.org/downloads/\n",
    "2. 安装 SK 包：`pip install semantic-kernel`\n",
    "3. 在项目目录创建 .env 文件，添加以下内容：\n",
    "\n",
    "```bash\n",
    "# .env\n",
    "OPENAI_API_KEY=\"\"\n",
    "OPENAI_API_BASE=\"\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=\"\"\n",
    "AZURE_OPENAI_ENDPOINT=\"\"\n",
    "AZURE_OPENAI_API_KEY=\"\"\n",
    "```\n",
    "\n",
    "OpenAI 和 Azure，配置好一个就行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Hello, World!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是一个简单示例。\n",
    "\n",
    "第一段代码是初始化。后面所有代码都要在执行过这段代码后，才能执行。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "import os\n",
    "\n",
    "# 加载 .env 到环境变量\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 创建 semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# 配置 OpenAI 服务\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "endpoint = os.getenv('OPENAI_API_BASE')\n",
    "model = OpenAIChatCompletion(\n",
    "    \"gpt-3.5-turbo\", api_key, endpoint=endpoint)\n",
    "\n",
    "# 把 LLM 服务加入 kernel\n",
    "# 可以加多个。第一个加入的会被默认使用，非默认的要被指定使用\n",
    "kernel.add_text_completion_service(\"my-gpt3\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行讲笑话的 prompt。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 semantic function\n",
    "tell_joke_about = kernel.create_semantic_function(\"给我讲个关于{{$input}}的笑话吧\")\n",
    "\n",
    "# 看结果\n",
    "print(tell_joke_about(\"Hello world\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>\n",
    "用我们熟悉的操作系统来类比，可以更好地理解 SK。\n",
    "<ol>\n",
    "<li>启动操作系统：<code>kernel = sk.Kernel()</code></li>\n",
    "<li>安装驱动程序：<code>kernel.add_xxx_service()</code></li>\n",
    "<li>安装应用程序：<code>func = kernel.create_semantic_function()</code></li>\n",
    "<li>运行应用程序：<code>func()</code></li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "基于 SK 开发的主要工作是写「应用程序」，也就是 Plugins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plugins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单说，plugin 就是一组函数的集合。它可以包含两种函数：\n",
    "\n",
    "- Semantic Functions - 语义函数，本质是 Prompt Engineering\n",
    "- Native Functions - 原生函数，类似 OpenAI 的 Function Calling\n",
    "\n",
    "值得一提的是，SK 的 plugin 会和 ChatGPT、Bing、Microsoft 365 通用。「很快」你用 SK 写的 plugin 就可以在这些平台上无缝使用了。这些平台上的 plugin 也可以通过 SK 被你调用。\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>注意：</b>Plugins 最初命名为 Skills，后来改为 Plugins。但是无论文档还是代码，都还有大量的「Skill」遗留。见到后，就知道两者是一回事就好\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Semantic Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Functions 是纯用数据（prompt + 描述）定义的，不需要编写任何代码。所以它与编程语言无关，可以被任何编程语言调用。\n",
    "\n",
    "一个典型的 semantic function 包含两个文件：\n",
    "\n",
    "- skprompt.txt: 存放 prompt，可以包含参数，还可以调用其它函数\n",
    "- config.json: 存放描述，包括函数功能，参数的数据类型，以及调用大模型时的参数\n",
    "\n",
    "举例：把 LangChain 「生成 Linux 命令」的例子用 SK 实现。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### skprompt.txt\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "将用户的指令转换成 Linux 命令\n",
    "\n",
    "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
    "\n",
    "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
    "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
    "\n",
    "Here is the output schema:\n",
    "```\n",
    "{\"properties\": {\"command\": {\"title\": \"Command\", \"description\": \"linux shell命令名\", \"type\": \"string\"}, \"arguments\": {\"title\": \"Arguments\", \"description\": \"命令的参数 (name:value)\", \"type\": \"object\", \"additionalProperties\": {\"type\": \"string\"}}}, \"required\": [\"command\", \"arguments\"]}\n",
    "```\n",
    "\n",
    "{{$input}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### config.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"schema\": 1,\n",
    "    \"type\": \"completion\",\n",
    "    \"description\": \"将用户的指令转换成 Linux 命令\",\n",
    "    \"completion\": {\n",
    "        \"max_tokens\": 256,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 0\n",
    "    },\n",
    "    \"input\": {\n",
    "        \"parameters\": [\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"description\": \"用户的指令\",\n",
    "                \"defaultValue\": \"\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面两个文件都在 [sk_samples/SamplePlugin/GenerateCommand](sk_samples/SamplePlugin/GenerateCommand/) 目录下。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 调用 Semantic Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 semantic function。注意目录结构\n",
    "functions = kernel.import_semantic_skill_from_directory(\n",
    "    \"./sk_samples/\", \"SamplePlugin\")\n",
    "cli = functions[\"GenerateCommand\"]\n",
    "\n",
    "# 看结果\n",
    "print(cli(\"将系统日期设为2023-04-01\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方提供了大量的 Semantic Functions 可以参考：https://github.com/microsoft/semantic-kernel/tree/main/samples/skills\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Semantic Kernel Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是个 VS Code 的插件，在 VS Code 里可以直接创建和调试 Semantic Function。\n",
    "\n",
    "安装地址：https://marketplace.visualstudio.com/items?itemName=ms-semantic-kernel.semantic-kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Native Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用编程语言写的函数，如果用 SK 的 Native Function 方式定义，就能纳入到 SK 的编排体系，可以被 Planner、其它 plugin 调用。\n",
    "\n",
    "下面，写一个过滤有害 Linux 命令的函数，和 GenerateCommand 组合使用。\n",
    "\n",
    "这个函数名是 `harmful_command`。如果输入的命令是有害的，就返回 `true`，否则返回 `false`。\n",
    "\n",
    "它也要放到目录结构中，在 [sk_samples/SamplePlugin/SamplePlugin.py](sk_samples/SamplePlugin/SamplePlugin.py) 里加入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为是代码，不是数据，所以必须 import\n",
    "from sk_samples.SamplePlugin.SamplePlugin import SamplePlugin\n",
    "\n",
    "# 加载 semantic function\n",
    "functions = kernel.import_semantic_skill_from_directory(\n",
    "    \"./sk_samples/\", \"SamplePlugin\")\n",
    "cli = functions[\"GenerateCommand\"]\n",
    "\n",
    "# 加载 native function\n",
    "functions = kernel.import_skill(SamplePlugin(), \"SamplePlugin\")\n",
    "harmful_command = functions[\"harmful_command\"]\n",
    "\n",
    "# 看结果\n",
    "command = cli(\"删除根目录下所有文件\")\n",
    "print(command)  # 这个 command 其实是 SKContext 类型\n",
    "print(harmful_command(context=command))  # 所以要传参给 context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 用 SKContext 实现多参数 Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果 Function 都只有一个参数，那么只要把参数定义为 `{{$input}}`，就可以按前面的例子来使用，比较直观。`{{$input}}`会默认被赋值。\n",
    "\n",
    "多参数时，就不能用默认机制了，需要定义 `SKContext` 类型的变量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为是代码，不是数据，所以必须 import\n",
    "from sk_samples.SamplePlugin.SamplePlugin import SamplePlugin\n",
    "\n",
    "# 加载 native function\n",
    "functions = kernel.import_skill(SamplePlugin(), \"SamplePlugin\")\n",
    "add = functions[\"add\"]\n",
    "\n",
    "# 看结果\n",
    "context = kernel.create_new_context()\n",
    "context[\"number1\"] = 1024\n",
    "context[\"number2\"] = 65536\n",
    "total = add(context=context)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 内置 Plugins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK 内置了若干好用的 plugin，但因为历史原因，它们叫 skill……\n",
    "\n",
    "加载方法：\n",
    "\n",
    "```python\n",
    "from semantic_kernel.core_skills import SkillName\n",
    "```\n",
    "\n",
    "它们是：\n",
    "\n",
    "- [`ConversationSummarySkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/conversation_summary_skill.py) - 生成对话的摘要\n",
    "- [`FileIOSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/file_io_skill.py) - 读写文件\n",
    "- [`HttpSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/http_skill.py) - 发出 HTTP 请求，支持 GET、POST、PUT 和 DELETE\n",
    "- [`MathSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/math_skill.py) - 加法和减法计算\n",
    "- [`TextMemorySkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/text_memory_skill.py) - 保存文本到 memory 中，可以对其做向量检索\n",
    "- [`TextSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/text_skill.py) - 把文本全部转为大写或小写，去掉头尾的空格（trim）\n",
    "- [`TimeSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/time_skill.py) - 获取当前时间及用多种格式获取时间参数\n",
    "- [`WaitSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/wait_skill.py) - 等待指定的时间\n",
    "- [`WebSearchEngineSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/web_search_engine_skill.py) - 在互联网上搜索给定的文本\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK 的 memory 使用非常简单：\n",
    "\n",
    "1. 用 `kernel.add_text_embedding_generation_service()` 添加一个文本向量生成服务\n",
    "2. 用 `kernel.register_memory_store()` 注册一个 memory store，可以是内存、文件、向量数据库等\n",
    "3. 用 `kernel.memory.save_information_async()` 保存信息到 memory store\n",
    "4. 用 `kernel.memory.search_async()` 搜索信息\n",
    "\n",
    "使用 ChatALL 的 README.md 做数据，使用内存作为 memory store，我们演示下基于文档对话。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 初始化 Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "import os\n",
    "\n",
    "# 加载 .env 到环境变量\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 创建 semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# 配置 OpenAI 服务\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "endpoint = os.getenv('OPENAI_API_BASE')\n",
    "model = OpenAIChatCompletion(\n",
    "    \"gpt-3.5-turbo\", api_key, endpoint=endpoint)\n",
    "\n",
    "# 把 LLM 服务加入 kernel\n",
    "# 可以加多个。第一个加入的会被默认使用，非默认的要被指定使用\n",
    "kernel.add_text_completion_service(\"my-gpt3\", model)\n",
    "\n",
    "# 添加 embedding 服务\n",
    "kernel.add_text_embedding_generation_service(\n",
    "    \"ada\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, endpoint=endpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 文本向量化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用内存做 memory store\n",
    "kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
    "\n",
    "# 读取文件内容\n",
    "with open('../05-langchain/ChatALL.md', 'r') as f:\n",
    "    # with open('sk_samples/SamplePlugin/SamplePlugin.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# 将文件内容分片，单片最大 100 token（注意：SK 的 text split 功能目前对中文支持不如对英文支持得好）\n",
    "lines = sk.text.split_markdown_lines(content, 100)\n",
    "\n",
    "# 将分片后的内容，存入内存\n",
    "for index, line in enumerate(lines):\n",
    "    await kernel.memory.save_information_async(\"chatall\", id=index, text=line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 向量搜索\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await kernel.memory.search_async(\"chatall\", \"ChatALL怎么下载？\")\n",
    "print(result[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pipeline / Chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK 更想用 pipeline 来描述 LangChain 中 chain 的概念，大概因为 pipeline 这个词更操作系统吧。但 chain 这个名词影响力太大，所以 SK 时不时也会用它。\n",
    "\n",
    "但是，SK 没有在代码里定义什么是 pipeline，它并不是一个类，或者函数什么的。它是贯彻整个 kernel 的一个概念。\n",
    "\n",
    "当一个 kernel 添加了 LLM、memory、functions，我们写下的 functions 之间的组合调用，就是个 pipeline 了。\n",
    "\n",
    "如果需要多条 pipeline，就定义多个 kernel。\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>思考：</b>LangChain 定义了好几种 Chain；SK 只是用 kernel 把抽象功能组合起来，pipeline 的过程完全交给开发者自己定义。你觉得哪种设计更好？\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在用 pipeline 思想把对话式搜索 ChatALL 的 README.md 功能做完整。\n",
    "\n",
    "要用到内置的 `TextMemorySkill`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入内置的 `TextMemorySkill`。主要使用它的 `recall()`\n",
    "kernel.import_skill(sk.core_skills.TextMemorySkill())\n",
    "\n",
    "# 直接在代码里创建 semantic function。里面调用了 `recall()`\n",
    "sk_prompt = \"\"\"\n",
    "基于下面的背景信息回答问题。如果背景信息为空，或者和问题不相关，请回答\"我不知道\"。\n",
    "\n",
    "[背景信息开始]\n",
    "{{recall $input}}\n",
    "[背景信息结束]\n",
    "\n",
    "问题：{{$input}}\n",
    "回答：\n",
    "\"\"\"\n",
    "ask = kernel.create_semantic_function(sk_prompt)\n",
    "\n",
    "# 提问\n",
    "context = kernel.create_new_context()\n",
    "context[sk.core_skills.TextMemorySkill.COLLECTION_PARAM] = \"chatall\"\n",
    "context[sk.core_skills.TextMemorySkill.RELEVANCE_PARAM] = 0.8\n",
    "context[\"input\"] = \"ChatALL 怎么下载？\"\n",
    "result = ask(context=context)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK 的 planner 概念上对标 LangChain 的 agent，但目前实现得还比较简单（C# 版丰富些）。\n",
    "\n",
    "SK Python 提供了三种 planner：\n",
    "\n",
    "1. `BasicPlanner` - 把任务拆解，自动调用各个函数，完成任务。它只是个用于基础验证的功能，最终会被 `SequentialPlanner` 替代。[Prompt 地址](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/basic_planner.py#L27-L123)\n",
    "2. `SequentialPlanner` - 开发中，未发布。比 `BasicPlanner` 更高级，但目标一致。[Prompt 地址](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/sequential_planner/Skills/SequentialPlanning/skprompt.txt)、[官方例程](https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/sequential_planner.py)\n",
    "3. `ActionPlanner` - 已发布。只输出 action，不执行。[Prompt 地址](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/action_planner/skprompt.txt)、[官方例程](https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/action_planner.py)\n",
    "\n",
    "来，把查周杰伦的生日是星期几，用 SK 的 `BasicPlanner` 再做一遍（版本 > 0.3.7dev 才能工作）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.core_skills import WebSearchEngineSkill, TimeSkill, MathSkill\n",
    "from semantic_kernel.connectors.search_engine import BingConnector\n",
    "from semantic_kernel.planning import BasicPlanner\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "import os\n",
    "\n",
    "# 加载 .env 到环境变量\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 创建 semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# 配置 OpenAI 服务\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "endpoint = os.getenv('OPENAI_API_BASE')\n",
    "model = OpenAIChatCompletion(\n",
    "    \"gpt-4\", api_key, endpoint=endpoint)    # GPT-4 才能完成此任务。不信改成 gpt-3.5-turbo 试试\n",
    "\n",
    "# 把 LLM 服务加入 kernel\n",
    "# 可以加多个。第一个加入的会被默认使用，非默认的要被指定使用\n",
    "kernel.add_text_completion_service(\"my-gpt4\", model)\n",
    "\n",
    "# 导入搜索 plugin\n",
    "connector = BingConnector(api_key=os.getenv(\"BING_API_KEY\"))\n",
    "kernel.import_skill(WebSearchEngineSkill(connector), \"WebSearch\")\n",
    "\n",
    "# 导入其它 plugin。所有被导入的 plugin，都是可以被 planner 调用的\n",
    "kernel.import_skill(MathSkill(), \"math\")\n",
    "kernel.import_skill(TimeSkill(), \"time\")\n",
    "\n",
    "# 创建 planner\n",
    "planner = BasicPlanner()\n",
    "\n",
    "# 开始\n",
    "ask = \"周杰伦的生日是星期几？\"\n",
    "plan = await planner.create_plan_async(ask, kernel)\n",
    "print(plan.generated_plan)\n",
    "result = await planner.execute_plan_async(plan, kernel)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain 和 Semantic Kernel 怎么选？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>\n",
    "<ol>\n",
    "<li>两者都值得学</li>\n",
    "<li>C#、JavaScript 和 Java 现在没得选</li>\n",
    "<li>做原型，首选 LangChain。功能多，开发快</li>\n",
    "<li>做产品，还是 SK 长期更可依赖</li>\n",
    "<li>建议只用 SK 的 Connectors 和 Plugins 能力，Planner 自己做</li>\n",
    "</ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 参与开源软件开发，正当时\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>为什么要为开源软件贡献代码：</b>\n",
    "<li>这是一个于己、于他人都有好处的共享事业</li>\n",
    "<li>大模型相关的开源软件都在起步阶段，有很多低垂的果实</li>\n",
    "<li>LangChain 和 SK 几乎对国产大模型都没有支持，这是好机会</li>\n",
    "<li>过程中能对机理了解更深</li>\n",
    "<li>在简历中是个亮色</li>\n",
    "</div>\n",
    "\n",
    "有些所谓技术高手号称给重要的开源软件贡献过代码，但深扒一下可以发现，只是改了改文档而已，写测试用例的都算深入了。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 怎么贡献\n",
    "\n",
    "### 准备\n",
    "\n",
    "1. 只能用英语\n",
    "2. 熟读贡献指导（[LangChain Python 版](https://github.com/hwchase17/langchain/blob/master/.github/CONTRIBUTING.md)、[LangChain JS 版](https://github.com/hwchase17/langchainjs/blob/main/CONTRIBUTING.md)、[Semantic Kernel](https://github.com/microsoft/semantic-kernel/blob/main/CONTRIBUTING.md)，了解详细的流程、要求、注意事项等\n",
    "\n",
    "如果以上两步不能坚持，此处可以放弃，也必须放弃了……\n",
    "\n",
    "### 选题\n",
    "\n",
    "1. 完善文档、做语言翻译是不错的起手式，可以体验下全流程。符合流程很重要，不然可能反倒是给人家添麻烦\n",
    "2. 从 issues 里面找一个你感兴趣的，或者自己提一个，最好是能解决实际问题的，询问项目维护人自己是否可以接这个 issue。得到同意，就可以动手了\n",
    "3. 国产大模型风起云涌，LangChain 和 SK 也需要支持更多的大模型，可以从这方面入手\n",
    "\n",
    "### 动手\n",
    "\n",
    "过程中肯定会遇到很多问题。技术上的，规范上的，语言上的等等。攻克这些问题，是很大的锻炼。\n",
    "\n",
    "代码被接受的那一刻，成就感是非常强的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LangChain.js 和 LangChain 保持了概念一致，功能丰富，很适合前端同学使用\n",
    "2. Semantic Kernel 架构设计更好，未来发展潜力更大，值得跟踪、尝试\n",
    "3. 趁它们都还不完善，正是参与开源软件建设的好时机\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 作业\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为自己选一个主攻方向吧，LangChain、LangChain.js 或 Semantic Kernel。然后用它来完成所有作业、项目。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课后调查\n",
    "\n",
    "请点击链接或扫码填写问卷，帮助我们持续改进课程内容。谢谢！\n",
    "\n",
    "https://agiclass.feishu.cn/share/base/form/shrcnU6ywdMDS2caxf6gp7dYQ63\n",
    "\n",
    "<img src=\"../survey.png\" width=\"200\" style=\"margin-left: 0px\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
